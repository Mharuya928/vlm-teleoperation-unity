# VLM Teleoperation for Unity (日本語版)

本プロジェクトは、Unity環境内で視覚言語モデル（VLM）を使用して車を制御する遠隔操作システムです。車のカメラから取得した映像を、[Ollama](https://ollama.com/)によってローカルで実行されるVLMに送信し、モデルからの自然言語またはJSON形式の応答を運転コマンドに変換して車両を制御します。

## 主な機能

- **VLMによる車両制御**: VLMがカメラ映像を認識し、状況に応じた判断（JSON形式）や指示（自然言語）を生成します。
- **多様なカメラビュー**: `VLMConfig`を通じて、一人称視点（FPS）、複数視点（Multi-View）、全周視点（Surround-View）などを動的に切り替え、VLMに与える視覚情報を変更できます。
- **ローカルLLM連携**: [Ollama](https://ollama.com/)を利用して、Qwen-VLなどの強力なVLMをローカル環境で実行します。
- **物理ベースの車両制御**: `CarController`が`WheelCollider`を用いて、リアルな車両の挙動（加速、操舵、ブレーキ、エンジンブレーキ）をシミュレートします。
- **センサー情報の活用**: `CarController`に搭載されたレイキャストやトリガーセンサーが障害物を検知し、その情報をUIやVLMの判断材料として利用できます。
- **柔軟な設定**: `ScriptableObject`として実装された`VLMConfig`により、使用するVLMモデル、プロンプト、カメラモードなどをUnityエディタ上で簡単に設定・変更できます。

## アーキテクチャ

1.  **カメラ撮影 (`VLMClient.cs`)**: ゲーム内に設置された複数のカメラ（前方・後方・左・右など）が車両の周囲を撮影します。
2.  **リクエスト送信 (`VLMClient.cs`)**: 撮影した画像をBase64形式にエンコードし、`VLMConfig`から取得したプロンプトと共にOllamaサーバーへ送信します。
3.  **VLMによる推論 (`Ollama`)**: Ollamaサーバーがリクエストを受け取り、指定されたVLM（例: `qwen2.5vl:7b`）で推論を実行し、応答を返します。
4.  **応答解釈と車両制御 (`VLMClient.cs` -> `CarController.cs`)**: `VLMClient`がVLMからの応答を受け取ります。（このプロジェクトでは主にコンソールやUIへの表示がメインですが、将来的には応答を解釈し、`CarController`の`Move`メソッドなどを呼び出すことで車両を自動制御することが可能です。）
5.  **車両の物理挙動 (`CarController.cs`)**: `Move`メソッドに渡されたモーター、ステアリング、ブレーキの入力値に基づき、各車輪の`WheelCollider`を制御して車両を動かします。

## セットアップと実行方法

### 必要なもの

-   **Unity**: Unity Hub と **Unity 2022.3.62f3** エディタ。
-   **Ollama**: システムにOllamaがインストールされ、実行されている必要があります。[公式サイト](https://ollama.com/)からダウンロードできます。

### 手順

1.  **リポジトリのクローン**:
    ```bash
    git clone https://github.com/sgmt-lab/vlm-teleoperation-unity.git
    ```
    > **✅ クローン時の認証エラーについて**
    > `git clone` 時に `Invalid username or token` や `Password authentication is not supported` といったエラーが表示された場合、以下の手順でGitHubの認証を行ってください。これは、現在パスワードでの認証が非推奨となっているためです。
    >
    > **推奨: GitHub CLI を使用する方法**
    >
    > 1.  **GitHub CLI (`gh`) をインストールします。**
    >     -   [公式インストール手順](https://github.com/cli/cli#installation)に従って、お使いのOSにインストールしてください。
    >
    > 2.  **ターミナルで以下のコマンドを実行し、認証を行います。**
    >     ```bash
    >     gh auth login
    >     ```
    >     -   いくつかの質問（どのGitHubアカウントか、SSHかHTTPSかなど）が表示されるので、指示に従って回答してください。ブラウザが開き、認証が完了します。
    >
    > 3.  **認証後、再度 `git clone` コマンドを実行します。**
    >     認証が済んでいれば、問題なくリポジトリをクローンできるはずです。


2.  **Ollamaのセットアップ**:
    VLMを実行するために、ローカルAI実行環境であるOllamaをセットアップします。

    **a. Ollamaのインストール**
    [公式サイト(ollama.com)](https://ollama.com/)にアクセスし、お使いのOS（macOS, Windows, Linux）に合ったインストーラーをダウンロードして実行してください。
    Linuxの場合は、ターミナルで以下のコマンドを実行することでもインストールできます。
    ```bash
    curl -fsSL https://ollama.com/install.sh | sh
    ```

    **b. Ollamaサーバーの起動と確認**
    インストール後、Ollamaは通常バックグラウンドサービスとして自動的に起動します。
    ターミナルで以下のコマンドを実行し、ヘルプメッセージが表示されれば正常にインストールされています。
    ```bash
    ollama
    ```

    **c. VLMモデルのダウンロード**
    次に、本プロジェクトで使用するVLM（視覚言語モデル）をダウンロードします。ターミナルで以下のコマンドを実行してください。このプロジェクトでは`Qwen 3VL 8B Instruct`モデルを推奨しています。
    ```bash
    ollama pull qwen3-vl:8b-instruct
    ```
    *補足: モデルのダウンロードには数分〜数十分かかる場合があります。なお、Unityプロジェクトの`OllamaModelManager`は、起動時にモデルが存在しない場合にこのコマンドを自動で実行する機能も持っています。*

    **d. 動作確認**
    ダウンロードが完了したら、以下のコマンドを実行して、ローカルに保存されているモデルの一覧を確認します。
    ```bash
    ollama list
    ```
    実行後、リストに`qwen3-vl:8b-instruct`が表示されていれば、Ollamaの準備は完了です。
    また、以下のコマンドでモデルを直接実行し、簡単な対話テストを行うこともできます。
    ```bash
    ollama run qwen3-vl:8b-instruct
    ```
    （モデルからの応答があれば成功です。終了するには `/bye` と入力してください。）

3.  **Unityのセットアップ**:
    **a. Unity Hubのインストール**
    まだUnity Hubをインストールしていない場合は、[Unity公式サイト](https://unity.com/download)からダウンロードしてインストールしてください。

    **b. Unity 2022.3.62f3 エディタの追加**
    Unity Hubを開き、「インストール」タブに移動します。「エディタをインストール」ボタンをクリックし、**Unity 2022.3.62f3**を検索してインストールします。

    **c. プロジェクトを開く**
    Unity Hubの「Projects」タブで「Add」をクリックし、クローンしたリポジトリのルートフォルダ（`vlm-teleoperation-unity`）を選択します。その後、リストに追加されたプロジェクトをクリックしてUnityエディタで開きます。

4.  **VLMConfigの設定**:
    -   Unityエディタの`Project`ウィンドウで、`Assets`フォルダ内にある`VLMConfig`アセット（例: `ConfigA`）を探します。
    -   インスペクタで、使用する`Selected Model`や、各`View Mode`に対応するプロンプトを編集します。

5.  **シーンの実行**:
    -   `Assets/Scenes`フォルダから`pitfalltask.unity`や`stairtask.unity`などのシーンを開きます。
    -   Unityエディタの上部にある再生ボタンを押して、シミュレーションを開始します。

## 主要スクリプト解説

### `VLMClient.cs`
このプロジェクトの司令塔となるスクリプトです。以下の役割を担います。

-   **VLMとの通信**: 設定されたカメラモードに応じて映像をキャプチャし、プロンプトと共にOllamaへリクエストを送信します。
-   **トリガー**: `Tab`キーによる手動実行、または障害物の自動検知による実行が可能です。
-   **設定管理**: `VLMConfig`アセットを切り替えることで、実験条件（A/Bテストなど）を簡単に変更できます。
-   **実験機能**: 推論時間や応答内容などをCSVファイルに記録する、ベンチマーク測定用の機能が実装されています。

### `CarController.cs`
車両の物理的な挙動全般を担当するスクリプトです。

-   **車両制御**: `Move`メソッドを通じて、外部（手動入力やAIのコマンド）からの指示に基づき、トルク、ブレーキ、ステアリングを`WheelCollider`に適用します。
-   **手動操作**: キーボードの入力（WASDキーや矢印キー）を検知し、`Move`メソッドに伝達します。
-   **センサー機能**:
    -   **レイキャスト**: 車両前方の障害物との距離を測定し、UIに表示します。
    -   **トリガー**: 車両に接触したオブジェクトを検知します。
-   **可視化**: デバッグ用に、レイキャストの範囲をシーンビュー上に線で描画します。

## 操作方法

-   **AIによる制御**:
    -   `Tab`キーを押すと、現在のカメラ映像がVLMに送信され、AIの応答が生成されます。（応答は主にコンソールやUIに出力されます。）

-   **手動操作**:
    -   **前進 / 後進**: `↑` / `↓` または `W` / `S`
    -   **左折 / 右折**: `←` / `→` または `A` / `D`
    -   **ブレーキ**: `スペース`キー
      （※UIの入力フィールドが選択されていない時に操作可能です。）
